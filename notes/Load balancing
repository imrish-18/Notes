Load balancing is a key concept in system design that ensures efficient distribution of incoming traffic or workloads across multiple servers or resources. The goal is to maximize throughput, minimize response time, and avoid overloading any single resource.

ğŸ”„ What Is Load Balancing?
Load balancing refers to the process of distributing incoming network traffic across multiple servers (also called nodes or instances) so that no single server bears too much demand. It is critical for building scalable and highly available systems.


âœ… Why Load Balancing?
âš–ï¸ Even distribution of load

ğŸš€ Improved performance and faster responses

ğŸ›¡ï¸ Fault tolerance & high availability

ğŸ“ˆ Scalabilityâ€”handle more users by adding more servers

ğŸ§  Health checksâ€”route traffic only to healthy nodes

ğŸ§  Types of Load Balancers
1. Hardware Load Balancers
Physical devices (expensive and used in large enterprises)

Example: F5 Big-IP, Cisco

2. Software Load Balancers
Run on commodity hardware or VMs

Examples: Nginx, HAProxy, Envoy

3. Cloud-based Load Balancers
Managed by cloud providers

Examples: AWS ELB, Azure Load Balancer, GCP Load Balancing


ğŸŒ Load Balancing      Algorithms
Algorithm	            Description
Round Robin	            Requests are distributed sequentially across servers
Least Connections	    New requests go to the server with the fewest active connections
IP Hash	                Hash of the client IP decides which server handles the request
Weighted	            Some servers get more traffic based on their "weight" (capacity)
Random	                Requests are sent to random servers
Consistent Hashing	    Helps maintain cache locality or session affinity


ğŸ“¦ Where Load Balancers Sit in Architecture
Client

Load Balancer

Web/Application Servers

Database

Optional: Multiple layers of load balancers (L4, L7)


ğŸ§± Types of Load Balancing by Layer
Layer 4 (Transport Layer): Based on TCP/UDP (e.g., IP + Port)

Layer 7 (Application Layer): Based on content (e.g., URL, headers, cookies)

âš™ï¸ Examples in System Design
Web App: A load balancer distributes traffic to multiple application servers.

Microservices: API Gateway or service mesh (e.g., Istio) handles load balancing.

Database: Read replicas can be load balanced for read-heavy systems.

ğŸ’¡ Best Practices
Use health checks

Implement failover mechanisms

Monitor server loads and scale horizontally

Combine with auto-scaling

Handle sticky sessions if needed




